{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv('C:\\\\Users\\\\Ankesh\\\\Desktop\\\\DS\\\\FILES\\\\kyphosis.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Kyphosis</th>\n",
       "      <th>Age</th>\n",
       "      <th>Number</th>\n",
       "      <th>Start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>absent</td>\n",
       "      <td>71</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>absent</td>\n",
       "      <td>158</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>present</td>\n",
       "      <td>128</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>absent</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>absent</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Kyphosis  Age  Number  Start\n",
       "0   absent   71       3      5\n",
       "1   absent  158       3     14\n",
       "2  present  128       4      5\n",
       "3   absent    2       5      1\n",
       "4   absent    1       4     15"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 81 entries, 0 to 80\n",
      "Data columns (total 4 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   Kyphosis  81 non-null     object\n",
      " 1   Age       81 non-null     int64 \n",
      " 2   Number    81 non-null     int64 \n",
      " 3   Start     81 non-null     int64 \n",
      "dtypes: int64(3), object(1)\n",
      "memory usage: 2.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.PairGrid at 0x1f4dc597048>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 540x540 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.pairplot(data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop('Kyphosis',axis=1)\n",
    "y=df['Kyphosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      absent       0.67      0.71      0.69        17\n",
      "     present       0.29      0.25      0.27         8\n",
      "\n",
      "    accuracy                           0.56        25\n",
      "   macro avg       0.48      0.48      0.48        25\n",
      "weighted avg       0.54      0.56      0.55        25\n",
      "\n",
      "[[12  5]\n",
      " [ 6  2]]\n"
     ]
    }
   ],
   "source": [
    "from  sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=101)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree=DecisionTreeClassifier()\n",
    "dtree.fit(x_train,y_train)\n",
    "predictions=dtree.predict(x_test)\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(y_test,predictions))\n",
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on DecisionTreeClassifier in module sklearn.tree._classes object:\n",
      "\n",
      "class DecisionTreeClassifier(sklearn.base.ClassifierMixin, BaseDecisionTree)\n",
      " |  DecisionTreeClassifier(criterion='gini', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, class_weight=None, presort='deprecated', ccp_alpha=0.0)\n",
      " |  \n",
      " |  A decision tree classifier.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <tree>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  criterion : {\"gini\", \"entropy\"}, default=\"gini\"\n",
      " |      The function to measure the quality of a split. Supported criteria are\n",
      " |      \"gini\" for the Gini impurity and \"entropy\" for the information gain.\n",
      " |  \n",
      " |  splitter : {\"best\", \"random\"}, default=\"best\"\n",
      " |      The strategy used to choose the split at each node. Supported\n",
      " |      strategies are \"best\" to choose the best split and \"random\" to choose\n",
      " |      the best random split.\n",
      " |  \n",
      " |  max_depth : int, default=None\n",
      " |      The maximum depth of the tree. If None, then nodes are expanded until\n",
      " |      all leaves are pure or until all leaves contain less than\n",
      " |      min_samples_split samples.\n",
      " |  \n",
      " |  min_samples_split : int or float, default=2\n",
      " |      The minimum number of samples required to split an internal node:\n",
      " |  \n",
      " |      - If int, then consider `min_samples_split` as the minimum number.\n",
      " |      - If float, then `min_samples_split` is a fraction and\n",
      " |        `ceil(min_samples_split * n_samples)` are the minimum\n",
      " |        number of samples for each split.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for fractions.\n",
      " |  \n",
      " |  min_samples_leaf : int or float, default=1\n",
      " |      The minimum number of samples required to be at a leaf node.\n",
      " |      A split point at any depth will only be considered if it leaves at\n",
      " |      least ``min_samples_leaf`` training samples in each of the left and\n",
      " |      right branches.  This may have the effect of smoothing the model,\n",
      " |      especially in regression.\n",
      " |  \n",
      " |      - If int, then consider `min_samples_leaf` as the minimum number.\n",
      " |      - If float, then `min_samples_leaf` is a fraction and\n",
      " |        `ceil(min_samples_leaf * n_samples)` are the minimum\n",
      " |        number of samples for each node.\n",
      " |  \n",
      " |      .. versionchanged:: 0.18\n",
      " |         Added float values for fractions.\n",
      " |  \n",
      " |  min_weight_fraction_leaf : float, default=0.0\n",
      " |      The minimum weighted fraction of the sum total of weights (of all\n",
      " |      the input samples) required to be at a leaf node. Samples have\n",
      " |      equal weight when sample_weight is not provided.\n",
      " |  \n",
      " |  max_features : int, float or {\"auto\", \"sqrt\", \"log2\"}, default=None\n",
      " |      The number of features to consider when looking for the best split:\n",
      " |  \n",
      " |          - If int, then consider `max_features` features at each split.\n",
      " |          - If float, then `max_features` is a fraction and\n",
      " |            `int(max_features * n_features)` features are considered at each\n",
      " |            split.\n",
      " |          - If \"auto\", then `max_features=sqrt(n_features)`.\n",
      " |          - If \"sqrt\", then `max_features=sqrt(n_features)`.\n",
      " |          - If \"log2\", then `max_features=log2(n_features)`.\n",
      " |          - If None, then `max_features=n_features`.\n",
      " |  \n",
      " |      Note: the search for a split does not stop until at least one\n",
      " |      valid partition of the node samples is found, even if it requires to\n",
      " |      effectively inspect more than ``max_features`` features.\n",
      " |  \n",
      " |  random_state : int or RandomState, default=None\n",
      " |      If int, random_state is the seed used by the random number generator;\n",
      " |      If RandomState instance, random_state is the random number generator;\n",
      " |      If None, the random number generator is the RandomState instance used\n",
      " |      by `np.random`.\n",
      " |  \n",
      " |  max_leaf_nodes : int, default=None\n",
      " |      Grow a tree with ``max_leaf_nodes`` in best-first fashion.\n",
      " |      Best nodes are defined as relative reduction in impurity.\n",
      " |      If None then unlimited number of leaf nodes.\n",
      " |  \n",
      " |  min_impurity_decrease : float, default=0.0\n",
      " |      A node will be split if this split induces a decrease of the impurity\n",
      " |      greater than or equal to this value.\n",
      " |  \n",
      " |      The weighted impurity decrease equation is the following::\n",
      " |  \n",
      " |          N_t / N * (impurity - N_t_R / N_t * right_impurity\n",
      " |                              - N_t_L / N_t * left_impurity)\n",
      " |  \n",
      " |      where ``N`` is the total number of samples, ``N_t`` is the number of\n",
      " |      samples at the current node, ``N_t_L`` is the number of samples in the\n",
      " |      left child, and ``N_t_R`` is the number of samples in the right child.\n",
      " |  \n",
      " |      ``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,\n",
      " |      if ``sample_weight`` is passed.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |  \n",
      " |  min_impurity_split : float, default=1e-7\n",
      " |      Threshold for early stopping in tree growth. A node will split\n",
      " |      if its impurity is above the threshold, otherwise it is a leaf.\n",
      " |  \n",
      " |      .. deprecated:: 0.19\n",
      " |         ``min_impurity_split`` has been deprecated in favor of\n",
      " |         ``min_impurity_decrease`` in 0.19. The default value of\n",
      " |         ``min_impurity_split`` will change from 1e-7 to 0 in 0.23 and it\n",
      " |         will be removed in 0.25. Use ``min_impurity_decrease`` instead.\n",
      " |  \n",
      " |  class_weight : dict, list of dict or \"balanced\", default=None\n",
      " |      Weights associated with classes in the form ``{class_label: weight}``.\n",
      " |      If None, all classes are supposed to have weight one. For\n",
      " |      multi-output problems, a list of dicts can be provided in the same\n",
      " |      order as the columns of y.\n",
      " |  \n",
      " |      Note that for multioutput (including multilabel) weights should be\n",
      " |      defined for each class of every column in its own dict. For example,\n",
      " |      for four-class multilabel classification weights should be\n",
      " |      [{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of\n",
      " |      [{1:1}, {2:5}, {3:1}, {4:1}].\n",
      " |  \n",
      " |      The \"balanced\" mode uses the values of y to automatically adjust\n",
      " |      weights inversely proportional to class frequencies in the input data\n",
      " |      as ``n_samples / (n_classes * np.bincount(y))``\n",
      " |  \n",
      " |      For multi-output, the weights of each column of y will be multiplied.\n",
      " |  \n",
      " |      Note that these weights will be multiplied with sample_weight (passed\n",
      " |      through the fit method) if sample_weight is specified.\n",
      " |  \n",
      " |  presort : deprecated, default='deprecated'\n",
      " |      This parameter is deprecated and will be removed in v0.24.\n",
      " |  \n",
      " |      .. deprecated:: 0.22\n",
      " |  \n",
      " |  ccp_alpha : non-negative float, default=0.0\n",
      " |      Complexity parameter used for Minimal Cost-Complexity Pruning. The\n",
      " |      subtree with the largest cost complexity that is smaller than\n",
      " |      ``ccp_alpha`` will be chosen. By default, no pruning is performed. See\n",
      " |      :ref:`minimal_cost_complexity_pruning` for details.\n",
      " |  \n",
      " |      .. versionadded:: 0.22\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  classes_ : ndarray of shape (n_classes,) or list of ndarray\n",
      " |      The classes labels (single output problem),\n",
      " |      or a list of arrays of class labels (multi-output problem).\n",
      " |  \n",
      " |  feature_importances_ : ndarray of shape (n_features,)\n",
      " |      The feature importances. The higher, the more important the\n",
      " |      feature. The importance of a feature is computed as the (normalized)\n",
      " |      total reduction of the criterion brought by that feature.  It is also\n",
      " |      known as the Gini importance [4]_.\n",
      " |  \n",
      " |  max_features_ : int\n",
      " |      The inferred value of max_features.\n",
      " |  \n",
      " |  n_classes_ : int or list of int\n",
      " |      The number of classes (for single output problems),\n",
      " |      or a list containing the number of classes for each\n",
      " |      output (for multi-output problems).\n",
      " |  \n",
      " |  n_features_ : int\n",
      " |      The number of features when ``fit`` is performed.\n",
      " |  \n",
      " |  n_outputs_ : int\n",
      " |      The number of outputs when ``fit`` is performed.\n",
      " |  \n",
      " |  tree_ : Tree\n",
      " |      The underlying Tree object. Please refer to\n",
      " |      ``help(sklearn.tree._tree.Tree)`` for attributes of Tree object and\n",
      " |      :ref:`sphx_glr_auto_examples_tree_plot_unveil_tree_structure.py`\n",
      " |      for basic usage of these attributes.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  DecisionTreeRegressor : A decision tree regressor.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  The default values for the parameters controlling the size of the trees\n",
      " |  (e.g. ``max_depth``, ``min_samples_leaf``, etc.) lead to fully grown and\n",
      " |  unpruned trees which can potentially be very large on some data sets. To\n",
      " |  reduce memory consumption, the complexity and size of the trees should be\n",
      " |  controlled by setting those parameter values.\n",
      " |  \n",
      " |  The features are always randomly permuted at each split. Therefore,\n",
      " |  the best found split may vary, even with the same training data and\n",
      " |  ``max_features=n_features``, if the improvement of the criterion is\n",
      " |  identical for several splits enumerated during the search of the best\n",
      " |  split. To obtain a deterministic behaviour during fitting,\n",
      " |  ``random_state`` has to be fixed.\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  \n",
      " |  .. [1] https://en.wikipedia.org/wiki/Decision_tree_learning\n",
      " |  \n",
      " |  .. [2] L. Breiman, J. Friedman, R. Olshen, and C. Stone, \"Classification\n",
      " |         and Regression Trees\", Wadsworth, Belmont, CA, 1984.\n",
      " |  \n",
      " |  .. [3] T. Hastie, R. Tibshirani and J. Friedman. \"Elements of Statistical\n",
      " |         Learning\", Springer, 2009.\n",
      " |  \n",
      " |  .. [4] L. Breiman, and A. Cutler, \"Random Forests\",\n",
      " |         https://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.datasets import load_iris\n",
      " |  >>> from sklearn.model_selection import cross_val_score\n",
      " |  >>> from sklearn.tree import DecisionTreeClassifier\n",
      " |  >>> clf = DecisionTreeClassifier(random_state=0)\n",
      " |  >>> iris = load_iris()\n",
      " |  >>> cross_val_score(clf, iris.data, iris.target, cv=10)\n",
      " |  ...                             # doctest: +SKIP\n",
      " |  ...\n",
      " |  array([ 1.     ,  0.93...,  0.86...,  0.93...,  0.93...,\n",
      " |          0.93...,  0.93...,  1.     ,  0.93...,  1.      ])\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      DecisionTreeClassifier\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      BaseDecisionTree\n",
      " |      sklearn.base.MultiOutputMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, criterion='gini', splitter='best', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=None, random_state=None, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, class_weight=None, presort='deprecated', ccp_alpha=0.0)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y, sample_weight=None, check_input=True, X_idx_sorted=None)\n",
      " |      Build a decision tree classifier from the training set (X, y).\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The training input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csc_matrix``.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          The target values (class labels) as integers or strings.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights. If None, then samples are equally weighted. Splits\n",
      " |          that would create child nodes with net zero or negative weight are\n",
      " |          ignored while searching for a split in each node. Splits are also\n",
      " |          ignored if they would result in any single class carrying a\n",
      " |          negative weight in either child node.\n",
      " |      \n",
      " |      check_input : bool, default=True\n",
      " |          Allow to bypass several input checking.\n",
      " |          Don't use this parameter unless you know what you do.\n",
      " |      \n",
      " |      X_idx_sorted : array-like of shape (n_samples, n_features),                 default=None\n",
      " |          The indexes of the sorted training input samples. If many tree\n",
      " |          are grown on the same dataset, this allows the ordering to be\n",
      " |          cached between trees. If None, the data will be sorted here.\n",
      " |          Don't use this parameter unless you know what to do.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : DecisionTreeClassifier\n",
      " |          Fitted estimator.\n",
      " |  \n",
      " |  predict_log_proba(self, X)\n",
      " |      Predict class log-probabilities of the input samples X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      proba : ndarray of shape (n_samples, n_classes) or list of n_outputs             such arrays if n_outputs > 1\n",
      " |          The class log-probabilities of the input samples. The order of the\n",
      " |          classes corresponds to that in the attribute :term:`classes_`.\n",
      " |  \n",
      " |  predict_proba(self, X, check_input=True)\n",
      " |      Predict class probabilities of the input samples X.\n",
      " |      \n",
      " |      The predicted class probability is the fraction of samples of the same\n",
      " |      class in a leaf.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      check_input : bool, default=True\n",
      " |          Allow to bypass several input checking.\n",
      " |          Don't use this parameter unless you know what you do.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      proba : ndarray of shape (n_samples, n_classes) or list of n_outputs             such arrays if n_outputs > 1\n",
      " |          The class probabilities of the input samples. The order of the\n",
      " |          classes corresponds to that in the attribute :term:`classes_`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True labels for X.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of self.predict(X) wrt. y.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from BaseDecisionTree:\n",
      " |  \n",
      " |  apply(self, X, check_input=True)\n",
      " |      Return the index of the leaf that each sample is predicted as.\n",
      " |      \n",
      " |      .. versionadded:: 0.17\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      check_input : bool, default=True\n",
      " |          Allow to bypass several input checking.\n",
      " |          Don't use this parameter unless you know what you do.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_leaves : array-like of shape (n_samples,)\n",
      " |          For each datapoint x in X, return the index of the leaf x\n",
      " |          ends up in. Leaves are numbered within\n",
      " |          ``[0; self.tree_.node_count)``, possibly with gaps in the\n",
      " |          numbering.\n",
      " |  \n",
      " |  cost_complexity_pruning_path(self, X, y, sample_weight=None)\n",
      " |      Compute the pruning path during Minimal Cost-Complexity Pruning.\n",
      " |      \n",
      " |      See :ref:`minimal_cost_complexity_pruning` for details on the pruning\n",
      " |      process.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The training input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csc_matrix``.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          The target values (class labels) as integers or strings.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights. If None, then samples are equally weighted. Splits\n",
      " |          that would create child nodes with net zero or negative weight are\n",
      " |          ignored while searching for a split in each node. Splits are also\n",
      " |          ignored if they would result in any single class carrying a\n",
      " |          negative weight in either child node.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      ccp_path : Bunch\n",
      " |          Dictionary-like object, with attributes:\n",
      " |      \n",
      " |          ccp_alphas : ndarray\n",
      " |              Effective alphas of subtree during pruning.\n",
      " |      \n",
      " |          impurities : ndarray\n",
      " |              Sum of the impurities of the subtree leaves for the\n",
      " |              corresponding alpha value in ``ccp_alphas``.\n",
      " |  \n",
      " |  decision_path(self, X, check_input=True)\n",
      " |      Return the decision path in the tree.\n",
      " |      \n",
      " |      .. versionadded:: 0.18\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      check_input : bool, default=True\n",
      " |          Allow to bypass several input checking.\n",
      " |          Don't use this parameter unless you know what you do.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      indicator : sparse matrix of shape (n_samples, n_nodes)\n",
      " |          Return a node indicator CSR matrix where non zero elements\n",
      " |          indicates that the samples goes through the nodes.\n",
      " |  \n",
      " |  get_depth(self)\n",
      " |      Return the depth of the decision tree.\n",
      " |      \n",
      " |      The depth of a tree is the maximum distance between the root\n",
      " |      and any leaf.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self.tree_.max_depth : int\n",
      " |          The maximum depth of the tree.\n",
      " |  \n",
      " |  get_n_leaves(self)\n",
      " |      Return the number of leaves of the decision tree.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self.tree_.n_leaves : int\n",
      " |          Number of leaves.\n",
      " |  \n",
      " |  predict(self, X, check_input=True)\n",
      " |      Predict class or regression value for X.\n",
      " |      \n",
      " |      For a classification model, the predicted class for each sample in X is\n",
      " |      returned. For a regression model, the predicted value based on X is\n",
      " |      returned.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features)\n",
      " |          The input samples. Internally, it will be converted to\n",
      " |          ``dtype=np.float32`` and if a sparse matrix is provided\n",
      " |          to a sparse ``csr_matrix``.\n",
      " |      \n",
      " |      check_input : bool, default=True\n",
      " |          Allow to bypass several input checking.\n",
      " |          Don't use this parameter unless you know what you do.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          The predicted classes, or the predict values.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from BaseDecisionTree:\n",
      " |  \n",
      " |  feature_importances_\n",
      " |      Return the feature importances.\n",
      " |      \n",
      " |      The importance of a feature is computed as the (normalized) total\n",
      " |      reduction of the criterion brought by that feature.\n",
      " |      It is also known as the Gini importance.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      feature_importances_ : ndarray of shape (n_features,)\n",
      " |          Normalized total reduction of criteria by feature\n",
      " |          (Gini importance).\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(dtree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      absent       0.74      1.00      0.85        17\n",
      "     present       1.00      0.25      0.40         8\n",
      "\n",
      "    accuracy                           0.76        25\n",
      "   macro avg       0.87      0.62      0.62        25\n",
      "weighted avg       0.82      0.76      0.71        25\n",
      "\n",
      "[[17  0]\n",
      " [ 6  2]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc=RandomForestClassifier(n_estimators=200)\n",
    "rfc.fit(x_train,y_train)\n",
    "predictions=rfc.predict(x_test)\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(classification_report(y_test,predictions))\n",
    "print(confusion_matrix(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********DECISION TREE******************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      absent       0.67      0.71      0.69        17\n",
      "     present       0.29      0.25      0.27         8\n",
      "\n",
      "    accuracy                           0.56        25\n",
      "   macro avg       0.48      0.48      0.48        25\n",
      "weighted avg       0.54      0.56      0.55        25\n",
      "\n",
      "[[12  5]\n",
      " [ 6  2]]\n",
      "0.56\n",
      "********RANDOM FOREST CLASSIFIER******************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      absent       0.74      1.00      0.85        17\n",
      "     present       1.00      0.25      0.40         8\n",
      "\n",
      "    accuracy                           0.76        25\n",
      "   macro avg       0.87      0.62      0.62        25\n",
      "weighted avg       0.82      0.76      0.71        25\n",
      "\n",
      "[[17  0]\n",
      " [ 6  2]]\n",
      "0.76\n"
     ]
    }
   ],
   "source": [
    "from  sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.3,random_state=101)\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree=DecisionTreeClassifier()\n",
    "dtree.fit(x_train,y_train)\n",
    "predictions=dtree.predict(x_test)\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "print('********DECISION TREE******************')\n",
    "print(classification_report(y_test,predictions))\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(accuracy_score(y_test, predictions))\n",
    "'''\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "regressor = RandomForestRegressor(n_estimators=20, random_state=0)\n",
    "regressor.fit(X_train, y_train)\n",
    "y_pred = regressor.predict(X_test)\n",
    "'''\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc=RandomForestClassifier(n_estimators=300)\n",
    "rfc.fit(x_train,y_train)\n",
    "predictions=rfc.predict(x_test)\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print('********RANDOM FOREST CLASSIFIER******************')\n",
    "print(classification_report(y_test,predictions))\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******ADA BOOST CLASSIFIER******************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      absent       0.68      1.00      0.81        17\n",
      "     present       0.00      0.00      0.00         8\n",
      "\n",
      "    accuracy                           0.68        25\n",
      "   macro avg       0.34      0.50      0.40        25\n",
      "weighted avg       0.46      0.68      0.55        25\n",
      "\n",
      "[[17  0]\n",
      " [ 8  0]]\n",
      "0.68\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ankesh\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "clf = AdaBoostClassifier(n_estimators=4, random_state=0, algorithm='SAMME')\n",
    "clf.fit(x_train,y_train)\n",
    "predictions=clf.predict(x_test)\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print('*******ADA BOOST CLASSIFIER******************')\n",
    "print(classification_report(y_test,predictions))\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******gradint BOOST CLASSIFIER******************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      absent       0.71      0.88      0.79        17\n",
      "     present       0.50      0.25      0.33         8\n",
      "\n",
      "    accuracy                           0.68        25\n",
      "   macro avg       0.61      0.57      0.56        25\n",
      "weighted avg       0.65      0.68      0.64        25\n",
      "\n",
      "[[15  2]\n",
      " [ 6  2]]\n",
      "0.68\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "# for regression\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "model = GradientBoostingRegressor(n_estimators=3,learning_rate=1)\n",
    "model.fit(X,Y)'''\n",
    "\n",
    "# for classification\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier()\n",
    "clf.fit(x_train,y_train)\n",
    "predictions=clf.predict(x_test)\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print('*******gradint BOOST CLASSIFIER******************')\n",
    "print(classification_report(y_test,predictions))\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(accuracy_score(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ankesh\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7666666666666666\n",
      "*******bagging******************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      absent       0.73      0.94      0.82        17\n",
      "     present       0.67      0.25      0.36         8\n",
      "\n",
      "    accuracy                           0.72        25\n",
      "   macro avg       0.70      0.60      0.59        25\n",
      "weighted avg       0.71      0.72      0.67        25\n",
      "\n",
      "[[16  1]\n",
      " [ 6  2]]\n",
      "0.72\n"
     ]
    }
   ],
   "source": [
    "# Bagged Decision Trees for Classification\n",
    "import pandas\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "cart = DecisionTreeClassifier()\n",
    "# no. of base classifier\n",
    "num_trees =100#B\n",
    "# bagging classifier\n",
    "model = BaggingClassifier(base_estimator=cart, n_estimators=num_trees, random_state=seed)\n",
    "results = model_selection.cross_val_score(model, x_test, y_test, cv=kfold)\n",
    "print(results.mean())\n",
    "model.fit(x_train,y_train)\n",
    "predictions=model.predict(x_test)\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print('*******bagging******************')\n",
    "print(classification_report(y_test,predictions))\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(accuracy_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 73.89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ankesh\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:296: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  FutureWarning\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=100)\n",
    "cart = DecisionTreeClassifier()\n",
    "results_kfold = model_selection.cross_val_score(cart, x,y, cv=kfold,verbose=1)\n",
    "print(\"Accuracy: %.2f%%\" % (results_kfold.mean()*100.0)) \n",
    "#cv_4_results = model_selection.cross_val_score(cart, x, y, cv=4,scoring=\"neg_mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(model_selection.cross_val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
